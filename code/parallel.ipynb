{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing made even simpler\n",
    "We've already seen some examples of multithreaded and distributed programming, and it was already pretty simple. Just slap a macro in front of your `for` loop.\n",
    "\n",
    "But the fun does not stop there. There are a couple of really nice packages that allow to define computations like folds (also known as Map-Reduce) and then to choose whether to run them single threaded, multithreaded or distributed (and even on the GPU).\n",
    "\n",
    "You may have to run the next cell to install a couple packages, otherwise skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"Folds\")\n",
    "Pkg.add(\"Transducers\")\n",
    "Pkg.add(\"Dagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Folds\n",
    "using Transducers\n",
    "using Distributed\n",
    "using Dagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Distributed` package allows us to get some processes to run our code in parallel using the `addprocs` function. Let's get four of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low level interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(2, 1, 6, ReentrantLock(nothing, 0x00000000, 0x00, Base.GenericCondition{Base.Threads.SpinLock}(Base.IntrusiveLinkedList{Task}(nothing, nothing), Base.Threads.SpinLock(0)), (0, 0, 0)), nothing)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# call `rand` on processor 2 with argument (2,2)\n",
    "r = remotecall(rand, 2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(2, 1, 7, ReentrantLock(nothing, 0x00000000, 0x00, Base.GenericCondition{Base.Threads.SpinLock}(Base.IntrusiveLinkedList{Task}(nothing, nothing), Base.Threads.SpinLock(0)), (8, 139737700013952, 0)), nothing)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate `1 .+ fetch(r)` on processor 2\n",
    "s = @spawnat 2 1 .+ fetch(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 1.78364  1.95816\n",
       " 1.90316  1.74173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetch(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(2, 1, 9, ReentrantLock(nothing, 0x00000000, 0x00, Base.GenericCondition{Base.Threads.SpinLock}(Base.IntrusiveLinkedList{Task}(nothing, nothing), Base.Threads.SpinLock(0)), (0, 139736901260560, 0)), nothing)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = @spawnat :any fetch(s)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 6.90807  6.90325\n",
       " 6.70935  6.76033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetch(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@everywhere` macro is used to make function definitions, as well as loading files/packages across all processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere norm2(x) = sum(abs2.(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work through an example of taking a serial loop and parallelising it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1464"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10000\n",
    "count = 0\n",
    "for i in 1:n\n",
    "    count += (norm2(rand(2)) < 1.0)\n",
    "end\n",
    "4 * count / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this kind of *Map-Reduce* style operations, we can use slap the `@distributed` macro in front of our loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 1000000\n",
    "count = @distributed (+) for i in 1:n\n",
    "    Int(norm2(rand(2)) < 1.0)\n",
    "end\n",
    "4 * count / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External variables can be used inside the loop, as long as they're read-only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499873.8555342362"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = rand(1000000)\n",
    "@distributed (+) for i in eachindex(a)\n",
    "    a[i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also use the `pmap` function which applies a function to each element of an iterator in parallel and return the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere collatz(n) = iseven(n) ? div(n,2) : 3n+1\n",
    "@everywhere function collatz_length(n)\n",
    "    count = 0\n",
    "    while  n != 1\n",
    "        n = collatz(n)\n",
    "        count += 1\n",
    "    end\n",
    "    count\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Vector{Int64}:\n",
       "   0\n",
       "   1\n",
       "   7\n",
       "   2\n",
       "   5\n",
       "   8\n",
       "  16\n",
       "   3\n",
       "  19\n",
       "   6\n",
       "   ⋮\n",
       " 111\n",
       "  93\n",
       "  23\n",
       "  23\n",
       "  49\n",
       "  49\n",
       "  49\n",
       "  49\n",
       " 111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pmap(collatz_length, 1:1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Arrays\n",
    "When trying to modify an array in-place in parallel, the following naive solution will not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = zeros(100)\n",
    "@distributed for i in eachindex(a)\n",
    "    a[i] = i\n",
    "end\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because, each process works on its own local copy of the array, not the true one. Instead, one should use a `SharedArray` which is a special array type shared across processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element SharedVector{Int64}:\n",
       "   1\n",
       "   2\n",
       "   3\n",
       "   4\n",
       "   5\n",
       "   6\n",
       "   7\n",
       "   8\n",
       "   9\n",
       "  10\n",
       "   ⋮\n",
       "  92\n",
       "  93\n",
       "  94\n",
       "  95\n",
       "  96\n",
       "  97\n",
       "  98\n",
       "  99\n",
       " 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using SharedArrays\n",
    "\n",
    "a = SharedArray{Int}(100)\n",
    "@distributed for i in eachindex(a)\n",
    "    a[i] = i\n",
    "end\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dagger to parallelize nested loops\n",
    "Beyond the standard library, the Dagger package provides some higher level interface for running things over multiple processes/servers.\n",
    "\n",
    "One notable thing Dagger can do is parallelize nested loops, which `@distributed` and `Threads.@threads` can't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant crn. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 2:\tWARNING: redefinition of constant crn. This may fail, cause incorrect answers, or produce other errors.\n",
      "      From worker 5:\tWARNING: redefinition of constant crn. This may fail, cause incorrect answers, or produce other errors.\n",
      "      From worker 4:\tWARNING: redefinition of constant crn. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 3:\tWARNING: redefinition of constant crn. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nested_dagger (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@everywhere begin\n",
    "    using Dagger\n",
    "    using Random\n",
    "    Random.seed!(0)\n",
    "\n",
    "    # Some \"expensive\" functions that complete at different speeds\n",
    "    const crn = abs.(randn(20, 7))\n",
    "    f(i) = sleep(crn[i, 7])\n",
    "    g(i, j, y) = sleep(crn[i, j])\n",
    "end\n",
    "function nested_dagger()\n",
    "    @sync for i in 1:20\n",
    "        y = Dagger.@spawn f(i)\n",
    "        for j in 1:6\n",
    "            z = Dagger.@spawn g(i, j, y)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dagger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, here's the two variants using only `@distributed`, parallelizing either the outer or inner loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nested_dist_inner (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function nested_dist_outer()\n",
    "    @distributed for i in 1:20\n",
    "        y = f(i)\n",
    "        for j in 1:6\n",
    "            z = g(i, j, y)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "function nested_dist_inner()\n",
    "    for i in 1:20\n",
    "        y = f(i)\n",
    "        @distributed for j in 1:6\n",
    "            z = g(i, j, y)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dist_outer() |> fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Folds and Transducers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple example, we'll try to compute the number of palindromic primes under $10^8$.\n",
    "\n",
    "Let's start by defining functions that return whether a given integer is a prime, or palindromic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function isprime(n)\n",
    "    k = 2\n",
    "    while k^2 <= n\n",
    "        if mod(n,k) == 0\n",
    "            return false\n",
    "        end\n",
    "        k += 1\n",
    "    end\n",
    "    return true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function ispalindromic(n)\n",
    "    let xs = digits(n)\n",
    "        xs == reverse(xs)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 10^8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two lines show different ways of computing what we want. The first one uses `Folds.sum` with the functionalities from `Transducers`, and must be read from left to right (the `|>` is the pipe operator).\n",
    "\n",
    "By default, `Folds` runs in multithreaded mode (which is pretty slow in this case because the notebook only has a single thread)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1:N |> Filter(isprime) |> Filter(ispalindromic) |> Map(n -> 1) |> Folds.sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next line uses the `foldxd` function from transducers, which does everything distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "foldxd(+, (1 for n in 1:N if isprime(n) && ispalindromic(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complicated Map-Reduce operations, the `FLoops` package allows for specifying a `for` loop with (almost) arbitrary operations, and it is compatible with the various execution modes from `Folds`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
